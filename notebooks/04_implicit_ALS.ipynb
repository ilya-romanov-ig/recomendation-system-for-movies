{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f142d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import implicit\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "from sklearn.utils import check_random_state\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23a20c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_seed = 42\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ee3852e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67760e0d",
   "metadata": {},
   "source": [
    "ALS implicit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7851bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(actual, predicted, k=10):\n",
    "    predicted_k = predicted[:k]\n",
    "    if len(predicted_k) == 0:\n",
    "        return 0.0\n",
    "    return len(set(predicted_k) & set(actual)) / k\n",
    "\n",
    "def recall_at_k(actual, predicted, k=10):\n",
    "    if len(actual) == 0:\n",
    "        return 0.0\n",
    "    predicted_k = predicted[:k]\n",
    "    return len(set(predicted_k) & set(actual)) / len(actual)\n",
    "\n",
    "def average_precision(actual, predicted, k=10):\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, p in enumerate(predicted[:k]):\n",
    "        if p in actual:\n",
    "            hits += 1\n",
    "            score += hits / (i + 1.0)\n",
    "    if not actual:\n",
    "        return 0.0\n",
    "    return score / min(len(actual), k)\n",
    "\n",
    "def ndcg_k(actual, predicted, k=10):\n",
    "    import math\n",
    "\n",
    "    def dcg(rel):\n",
    "        return sum((1.0 / math.log2(i + 2)) for i, r in enumerate(rel) if r == 1)\n",
    "\n",
    "    predicted_k = predicted[:k]\n",
    "    rel = [1 if p in actual else 0 for p in predicted_k]\n",
    "    idcg = dcg(sorted(rel, reverse=True))\n",
    "    dcg_val = dcg(rel)\n",
    "    return dcg_val / idcg if idcg > 0 else 0.0\n",
    "\n",
    "def train_model(train_matrix, factors=50, regularization=0.01, iterations=15, random_state=42, alpha=40):\n",
    "    matrix = train_matrix.tocsr().astype(np.float32)\n",
    "    confidence_matrix = matrix.multiply(alpha).tocsr()\n",
    "\n",
    "    model = implicit.als.AlternatingLeastSquares(\n",
    "        factors=int(factors), \n",
    "        regularization=float(regularization),\n",
    "        iterations=int(iterations),\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    model.fit(confidence_matrix)\n",
    "    return model\n",
    "\n",
    "def create_compatible_matrix(original_matrix, target_rows, target_cols):\n",
    "    new_matrix = csr_matrix((target_rows, target_cols), dtype=np.float32)\n",
    "    rows_to_copy = min(original_matrix.shape[0], target_rows)\n",
    "    cols_to_copy = min(original_matrix.shape[1], target_cols)\n",
    "    new_matrix[:rows_to_copy, :cols_to_copy] = original_matrix[:rows_to_copy, :cols_to_copy]\n",
    "    return new_matrix\n",
    "\n",
    "def evaluate_model_topk(model, train_matrix, test_matrix, K=10):\n",
    "    num_users_model = model.user_factors.shape[0]\n",
    "    num_items_model = model.item_factors.shape[0]\n",
    "    \n",
    "    train_compatible = create_compatible_matrix(train_matrix, num_users_model, num_items_model)\n",
    "    test_compatible = create_compatible_matrix(test_matrix, num_users_model, num_items_model)\n",
    "    \n",
    "    test_csr = test_compatible.tocsr()\n",
    "    train_csr = train_compatible.tocsr()\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    maps = []\n",
    "    ndcgs = []\n",
    "\n",
    "    for user in range(num_users_model):\n",
    "        if user >= test_csr.shape[0]:\n",
    "            continue\n",
    "            \n",
    "        actual_items = test_csr[user].indices.tolist()\n",
    "\n",
    "        if len(actual_items) == 0:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            recommended, _ = model.recommend(\n",
    "                user,\n",
    "                train_csr,\n",
    "                N=K,\n",
    "                filter_already_liked_items=True\n",
    "            )\n",
    "\n",
    "            precisions.append(precision_at_k(actual_items, recommended, K))\n",
    "            recalls.append(recall_at_k(actual_items, recommended, K))\n",
    "            maps.append(average_precision(actual_items, recommended, K))\n",
    "            ndcgs.append(ndcg_k(actual_items, recommended, K))\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    if not precisions:\n",
    "        return {\n",
    "            \"precision@K\": 0.0,\n",
    "            \"recall@K\": 0.0,\n",
    "            \"map@K\": 0.0,\n",
    "            \"ndcg@K\": 0.0,\n",
    "        }\n",
    "\n",
    "    return {\n",
    "        \"precision@K\": float(np.mean(precisions)),\n",
    "        \"recall@K\": float(np.mean(recalls)),\n",
    "        \"map@K\": float(np.mean(maps)),\n",
    "        \"ndcg@K\": float(np.mean(ndcgs)),\n",
    "    }\n",
    "\n",
    "def model_grid_search(train_matrix, test_matrix, param_distributions, n_iter=10, random_state=42, K=10):\n",
    "    best_score = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    results = []\n",
    "\n",
    "    rng = check_random_state(random_state)\n",
    "    param_names = list(param_distributions.keys())\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        params = {name: rng.choice(param_distributions[name]) for name in param_names}\n",
    "\n",
    "        try:\n",
    "            model = train_model(\n",
    "                train_matrix,\n",
    "                factors=int(params.get('factors', 50)),\n",
    "                regularization=float(params.get('regularization', 0.01)), \n",
    "                iterations=int(params.get('iterations', 15)), \n",
    "                random_state=random_state\n",
    "            )\n",
    "\n",
    "            metrics = evaluate_model_topk(model, train_matrix, test_matrix, K)\n",
    "            score = metrics[\"ndcg@K\"]\n",
    "\n",
    "            results.append({\n",
    "                \"params\": params.copy(),\n",
    "                \"metrics\": metrics,\n",
    "                \"iteration\": i\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_params = params.copy()\n",
    "            best_model = model\n",
    "\n",
    "    if results:\n",
    "        results.sort(key=lambda x: x['metrics']['ndcg@K'], reverse=True)\n",
    "    else:\n",
    "        print(\"Не удалось выполнить ни одной итерации\")\n",
    "\n",
    "    return best_model, best_params, best_score, results\n",
    "\n",
    "def recommend_for_user(model, train_matrix, user_id, user_to_idx, movie_to_idx, n=10, filter_liked=True):\n",
    "    if user_id not in user_to_idx:\n",
    "        raise ValueError(f\"Пользователь {user_id} не найден в словаре\")\n",
    "    \n",
    "    user_idx = user_to_idx[user_id]\n",
    "    num_users_model = model.user_factors.shape[0]\n",
    "    num_items_model = model.item_factors.shape[0]\n",
    "    \n",
    "    if user_idx >= num_users_model:\n",
    "        raise ValueError(f\"Индекс пользователя {user_idx} превышает размер модели\")\n",
    "    \n",
    "    train_compatible = create_compatible_matrix(train_matrix, num_users_model, num_items_model)\n",
    "    user_items = train_compatible.tocsr()\n",
    "\n",
    "    if filter_liked:\n",
    "        recommendations = model.recommend(\n",
    "            user_idx,\n",
    "            user_items,\n",
    "            N=n,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "    else:\n",
    "        recommendations = model.recommend(user_idx, user_items, N=n, filter_already_liked_items=False)\n",
    "\n",
    "    idx_to_movie = {idx: movie_id for movie_id, idx in movie_to_idx.items()}\n",
    "\n",
    "    recommended_items = []\n",
    "    for item_idx, score in zip(recommendations[0], recommendations[1]):\n",
    "        if item_idx in idx_to_movie:\n",
    "            movie_id = idx_to_movie[item_idx]\n",
    "            recommended_items.append((movie_id, float(score)))\n",
    "\n",
    "    return recommended_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6ac5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "from src.data_preprocessing import train_test_split_by_user, create_rating_matrix\n",
    "\n",
    "matrix, user_to_idx, movie_to_idx, user_ids, movie_ids= create_rating_matrix(df)\n",
    "\n",
    "train_matrix, test_matrix = train_test_split_by_user(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50d39fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 27.94it/s]\n",
      "100%|██████████| 100/100 [00:03<00:00, 27.22it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 31.95it/s]\n",
      "100%|██████████| 50/50 [00:01<00:00, 29.61it/s]\n",
      "100%|██████████| 100/100 [00:04<00:00, 23.44it/s]\n"
     ]
    }
   ],
   "source": [
    "param_distributions = {\n",
    "    'factors': [50, 100, 150, 200], \n",
    "    'regularization': [0.001, 0.01, 0.1, 1.0],  \n",
    "    'iterations': [20, 30, 50, 100], \n",
    "}\n",
    "best_model, best_params, best_score, results = model_grid_search(train_matrix, test_matrix, param_distributions, n_iter=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "01858483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ЛУЧШИЕ ПАРАМЕТРЫ:\n",
      "Параметры: {'factors': np.int64(150), 'regularization': np.float64(1.0), 'iterations': np.int64(20)}\n",
      "Лучший NDCG@K: 0.0000\n",
      "\n",
      "ТОП-5 лучших комбинаций:\n",
      "1. Параметры: {'factors': np.int64(150), 'regularization': np.float64(1.0), 'iterations': np.int64(20)}\n",
      "   Precision@K: 0.0000, Recall@K: 0.0000\n",
      "   MAP@K: 0.0000, NDCG@K: 0.0000\n",
      "2. Параметры: {'factors': np.int64(150), 'regularization': np.float64(0.1), 'iterations': np.int64(100)}\n",
      "   Precision@K: 0.0000, Recall@K: 0.0000\n",
      "   MAP@K: 0.0000, NDCG@K: 0.0000\n",
      "3. Параметры: {'factors': np.int64(50), 'regularization': np.float64(0.001), 'iterations': np.int64(50)}\n",
      "   Precision@K: 0.0000, Recall@K: 0.0000\n",
      "   MAP@K: 0.0000, NDCG@K: 0.0000\n",
      "4. Параметры: {'factors': np.int64(100), 'regularization': np.float64(0.1), 'iterations': np.int64(50)}\n",
      "   Precision@K: 0.0000, Recall@K: 0.0000\n",
      "   MAP@K: 0.0000, NDCG@K: 0.0000\n",
      "5. Параметры: {'factors': np.int64(150), 'regularization': np.float64(0.1), 'iterations': np.int64(100)}\n",
      "   Precision@K: 0.0000, Recall@K: 0.0000\n",
      "   MAP@K: 0.0000, NDCG@K: 0.0000\n",
      "\n",
      "Рекомендации для пользователя 1:\n",
      "  Фильм 32: оценка 1.0790\n",
      "  Фильм 1580: оценка 1.0775\n",
      "  Фильм 367: оценка 1.0320\n",
      "  Фильм 1089: оценка 1.0217\n",
      "  Фильм 1213: оценка 1.0208\n"
     ]
    }
   ],
   "source": [
    "print(\"ЛУЧШИЕ ПАРАМЕТРЫ:\")\n",
    "print(f\"Параметры: {best_params}\")\n",
    "print(f\"Лучший NDCG@K: {best_score:.4f}\")\n",
    "\n",
    "print(\"\\nТОП-5 лучших комбинаций:\")\n",
    "for i, result in enumerate(results[:5]):\n",
    "    print(f\"{i+1}. Параметры: {result['params']}\")\n",
    "    print(f\"   Precision@K: {result['metrics']['precision@K']:.4f}, Recall@K: {result['metrics']['recall@K']:.4f}\")\n",
    "    print(f\"   MAP@K: {result['metrics']['map@K']:.4f}, NDCG@K: {result['metrics']['ndcg@K']:.4f}\")\n",
    "\n",
    "try:\n",
    "    user_id = df['userId'].iloc[0]\n",
    "    recommendations = recommend_for_user(best_model, train_matrix, user_id, user_to_idx, movie_to_idx, n=5, filter_liked=False)\n",
    "    print(f\"\\nРекомендации для пользователя {user_id}:\")\n",
    "    for movie_id, score in recommendations:\n",
    "        print(f\"  Фильм {movie_id}: оценка {score:.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nОшибка рекомендаций: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
